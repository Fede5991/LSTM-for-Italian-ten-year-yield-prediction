{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Ten-year Italy yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import LSTM,Conv2D,Flatten\n",
    "from keras.layers import Dense,Dropout\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = pd.read_csv(\"Rendimenti_italia_giornaliero.csv\",header=None,sep=\";\")\n",
    "weekly_data = pd.read_csv(\"Rendimenti_italia.csv\",header=None,sep=\";\")\n",
    "germany_daily_data = pd.read_csv(\"Rendimenti_germania_giornaliero.csv\",header=None,sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data=weekly_data[::-1]\n",
    "weekly_data.columns=['Data','Close','Open','High','Low','Variation']\n",
    "weekly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Candlestick(x=weekly_data['Data'],\n",
    "                open=weekly_data['Open'], high=weekly_data['High'],\n",
    "                low=weekly_data['Low'], close=weekly_data['Close'])])\n",
    "fig.update_layout(\n",
    "    title='Ten-year Italy yield',\n",
    "    yaxis_title='',\n",
    "    width=768)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data=daily_data[::-1]\n",
    "daily_data.columns=['Data','Close','Open','High','Low','Variation']\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germany_daily_data=germany_daily_data[::-1]\n",
    "germany_daily_data.columns=['Data','Close','Open','High','Low','Variation']\n",
    "i=germany_daily_data[germany_daily_data['Data']=='01.12.2009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Months=np.zeros((len(daily_data['Close']),5))\n",
    "labels=['Close','Open','High','Low']\n",
    "for i in tqdm(range(len(daily_data['Close'])-1)):\n",
    "    k=0\n",
    "    for j in labels:\n",
    "        value=float(daily_data[j][len(daily_data[j])-1-i][0])\n",
    "        value2=float(daily_data[j][len(daily_data[j])-1-i][2:])\n",
    "        Months[i,k]=value+value2/1000\n",
    "        k+=1\n",
    "    l=0\n",
    "    while daily_data['Variation'][len(daily_data['Variation'])-1-i][l]!=',':\n",
    "        l+=1\n",
    "    if daily_data['Variation'][len(daily_data['Variation'])-1-i][0]=='-':\n",
    "        number1=float(daily_data['Variation'][len(daily_data['Variation'])-1-i][1:l])\n",
    "    else:\n",
    "        number1=float(daily_data['Variation'][len(daily_data['Variation'])-1-i][0:l])\n",
    "    number2=float(daily_data['Variation'][len(daily_data['Variation'])-1-i][l+1:-1])\n",
    "    Months[i,k]=number1+number2/100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=30#number of days in the history\n",
    "horizon=5\n",
    "X_train=np.zeros((len(daily_data['Close'])-chosen-365,chosen,4))\n",
    "Y_train=np.zeros((len(daily_data['Close'])-chosen-365,2))\n",
    "X_val=np.zeros((365,chosen,4))\n",
    "Y_val=np.zeros((365,2))\n",
    "z=0\n",
    "print (\"Creation of the training data:\\n\")\n",
    "for i in tqdm(range(len(daily_data['Close'])-chosen-365-horizon)):\n",
    "    for j in range(chosen):\n",
    "        X_train[z,j,0]=Months[i+j,0]\n",
    "        X_train[z,j,1]=Months[i+j,1]\n",
    "        X_train[z,j,2]=Months[i+j,2]\n",
    "        X_train[z,j,3]=Months[i+j,3]\n",
    "        #X_train[z,j,4]=Months[i+j,4]\n",
    "    candidates = []\n",
    "    for k in range(horizon):\n",
    "        candidates.append(Months[i+chosen+k,2])\n",
    "    Y_train[z,0]=np.max(candidates)\n",
    "    candidates = []\n",
    "    for k in range(horizon):\n",
    "        candidates.append(Months[i+chosen+k,3])\n",
    "    Y_train[z,1]=np.min(candidates)\n",
    "    z+=1\n",
    "z=0\n",
    "print (\"Creation of the validation data:\\n\")\n",
    "for i in tqdm(range(365)):\n",
    "    for j in range(chosen):\n",
    "        X_val[z,j,0]=Months[i+j+len(daily_data['Close'])-chosen-365-horizon,0]\n",
    "        X_val[z,j,1]=Months[i+j+len(daily_data['Close'])-chosen-365-horizon,1]\n",
    "        X_val[z,j,2]=Months[i+j+len(daily_data['Close'])-chosen-365-horizon,2]\n",
    "        X_val[z,j,3]=Months[i+j+len(daily_data['Close'])-chosen-365-horizon,3]\n",
    "        #X_val[z,j,4]=Months[i+j+len(daily_data['Close'])-chosen-365-horizon,4]\n",
    "    candidates = []\n",
    "    for k in range(horizon):\n",
    "        candidates.append(Months[i+len(daily_data['Close'])-365-horizon+k,2])\n",
    "    Y_val[z,0]=np.max(candidates)\n",
    "    candidates = []\n",
    "    for k in range(horizon):\n",
    "        candidates.append(Months[i+len(daily_data['Close'])-365-horizon+k,3])\n",
    "    Y_val[z,1]=np.min(candidates)\n",
    "    z+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Fede\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "#del model\n",
    "chosen=30\n",
    "#X_train=X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2]))\n",
    "#X_val=X_val.reshape((X_val.shape[0],X_val.shape[1],X_val.shape[2]))\n",
    "#print (X_train.shape)\n",
    "#print (X_val.shape)\n",
    "#print (Y_train.shape)\n",
    "#print (Y_val.shape)\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(10,kernel_size=(1,5),strides=(1,5),activation='relu'))\n",
    "model.add(LSTM(30, return_sequences=1,activation='relu'))\n",
    "model.add(LSTM(30,activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#history=model.fit(X_train,Y_train,epochs=20,verbose=0,callbacks=[TQDMNotebookCallback()],shuffle=True,validation_data=(X_val,Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "epochs=np.arange(20)\n",
    "plt.plot(epochs,history.history['loss'],label='Train loss')\n",
    "plt.plot(epochs,history.history['val_loss'],label='Val loss')\n",
    "plt.grid()\n",
    "plt.title('Losses')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(12,6))\n",
    "days=np.arange(365)\n",
    "plt.plot(days,Y_val[:,0],label='True behavior high',color='green')\n",
    "plt.plot(days,Y_val[:,1],label='True behavior low',color='red')\n",
    "plt.plot(days,model.predict(X_val)[:,0],label='Predicted high',color='lightgreen')\n",
    "plt.plot(days,model.predict(X_val)[:,1],label='Predicted low',color='orange')\n",
    "plt.grid()\n",
    "plt.title('Rendimento reale e predetto del decennale italiano negli ultimi 365 giorni')\n",
    "plt.ylabel('Rendimento')\n",
    "plt.xlabel('Giorni ultimo anno')\n",
    "plt.legend()\n",
    "plt.savefig('Predizione_2_giorni.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 3 layers into a model with 0 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9834314ad78b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdaily_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Last.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdaily_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Open'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'High'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Low'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdaily_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                          \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                          \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 3 layers into a model with 0 layers."
     ]
    }
   ],
   "source": [
    "model.load_weights('model.h5')\n",
    "daily_data = pd.read_csv(\"Last.csv\",header=None,sep=\";\")\n",
    "daily_data.columns=['Data','Close','Open','High','Low']\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM = np.zeros((30,4))\n",
    "for i in range(30):\n",
    "    LM[i,0]=float(daily_data['Close'][29-i][0]+'.'+daily_data['Close'][29-i][2:])\n",
    "    LM[i,1]=float(daily_data['Open'][29-i][0]+'.'+daily_data['Open'][29-i][2:])\n",
    "    LM[i,2]=float(daily_data['High'][29-i][0]+'.'+daily_data['High'][29-i][2:])\n",
    "    LM[i,3]=float(daily_data['Low'][29-i][0]+'.'+daily_data['Low'][29-i][2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('Prediction.h5')\n",
    "print (model.predict(LM.reshape(1,30,4)))\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(LM[25:])\n",
    "plt.scatter([5],model.predict(LM.reshape(1,30,4))[0,0],color='green')\n",
    "plt.scatter([5],model.predict(LM.reshape(1,30,4))[0,1],color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
